{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from access_token import ACCESS_TOKEN\n",
    "owner, repo = 'tensorflow', 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using perceval Github backend from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-03-24 07:27:48,462] - Sir Perceval is on his quest.\n",
      "[2019-03-24 07:28:20,745] - Fetching commits: 'https://github.com/tensorflow/datasets' git repository from 1970-01-01 00:00:00+00:00 to 2100-01-01 00:00:00+00:00; all branches\n",
      "[2019-03-24 07:28:24,825] - Fetch process completed: 696 commits fetched\n",
      "[2019-03-24 07:28:24,826] - Sir Perceval completed his quest.\n",
      "[2019-03-24 07:28:25,497] - Sir Perceval is on his quest.\n",
      "[2019-03-24 07:28:30,880] - Getting info for https://api.github.com/users/piyush-kgp\n",
      "[2019-03-24 07:28:32,340] - Getting info for https://api.github.com/users/rsepassi\n",
      "[2019-03-24 07:28:33,856] - Getting info for https://api.github.com/users/tiaguinho\n",
      "[2019-03-24 07:28:35,314] - Getting info for https://api.github.com/users/LoSealL\n",
      "[2019-03-24 07:28:36,798] - Getting info for https://api.github.com/users/ksachdeva\n",
      "[2019-03-24 07:28:38,313] - Getting info for https://api.github.com/users/brettkoonce\n",
      "[2019-03-24 07:28:39,336] - Getting info for https://api.github.com/users/MareoRaft\n",
      "[2019-03-24 07:28:41,287] - Getting info for https://api.github.com/users/Conchylicultor\n",
      "[2019-03-24 07:28:42,908] - Getting info for https://api.github.com/users/RicCu\n",
      "[2019-03-24 07:28:44,954] - Getting info for https://api.github.com/users/mr-ubik\n",
      "[2019-03-24 07:28:47,225] - Getting info for https://api.github.com/users/lc0\n",
      "[2019-03-24 07:28:49,418] - Getting info for https://api.github.com/users/dynamicwebpaige\n",
      "[2019-03-24 07:28:50,912] - Getting info for https://api.github.com/users/rodrigob\n",
      "[2019-03-24 07:28:52,039] - Getting info for https://api.github.com/users/pierrot0\n",
      "[2019-03-24 07:28:53,588] - Getting info for https://api.github.com/users/VikramTiwari\n",
      "[2019-03-24 07:28:55,124] - Getting info for https://api.github.com/users/rudifus\n",
      "[2019-03-24 07:28:56,114] - Getting info for https://api.github.com/users/bhack\n",
      "[2019-03-24 07:28:57,419] - Getting info for https://api.github.com/users/calledbymountains\n",
      "[2019-03-24 07:28:58,404] - Getting info for https://api.github.com/users/jackd\n",
      "[2019-03-24 07:29:00,054] - Getting info for https://api.github.com/users/madiator\n",
      "[2019-03-24 07:29:02,858] - Getting info for https://api.github.com/users/agonza1\n",
      "[2019-03-24 07:29:03,892] - Getting info for https://api.github.com/users/cagbal\n",
      "[2019-03-24 07:29:04,895] - Getting info for https://api.github.com/users/lamnguyen95\n",
      "[2019-03-24 07:29:05,818] - Getting info for https://api.github.com/users/danieljanes\n",
      "[2019-03-24 07:29:06,854] - Getting info for https://api.github.com/users/DeadlyBunny24\n",
      "[2019-03-24 07:29:08,972] - Getting info for https://api.github.com/users/slerman12\n",
      "[2019-03-24 07:29:10,485] - Getting info for https://api.github.com/users/suvarnak\n",
      "[2019-03-24 07:29:13,057] - Getting info for https://api.github.com/users/leriomaggio\n",
      "[2019-03-24 07:29:14,575] - Getting info for https://api.github.com/users/Worthy7\n",
      "[2019-03-24 07:29:15,986] - Getting info for https://api.github.com/users/wookayin\n",
      "[2019-03-24 07:29:17,021] - Getting info for https://api.github.com/users/pzelasko\n",
      "[2019-03-24 07:29:18,235] - Getting info for https://api.github.com/users/patzm\n",
      "[2019-03-24 07:29:19,193] - Getting info for https://api.github.com/users/ghchinoy\n",
      "[2019-03-24 07:29:20,710] - Getting info for https://api.github.com/users/mehmedes\n",
      "[2019-03-24 07:29:22,937] - Getting info for https://api.github.com/users/gongliyu\n",
      "[2019-03-24 07:29:24,472] - Getting info for https://api.github.com/users/frthjf\n",
      "[2019-03-24 07:29:25,520] - Getting info for https://api.github.com/users/cyfra\n",
      "[2019-03-24 07:29:26,534] - Getting info for https://api.github.com/users/kovasb\n",
      "[2019-03-24 07:29:28,074] - Getting info for https://api.github.com/users/lgeiger\n",
      "[2019-03-24 07:29:29,603] - Getting info for https://api.github.com/users/samsamoa\n",
      "[2019-03-24 07:29:32,752] - Getting info for https://api.github.com/users/tarrade\n",
      "[2019-03-24 07:29:36,288] - Getting info for https://api.github.com/users/cbfinn\n",
      "[2019-03-24 07:29:37,326] - Getting info for https://api.github.com/users/nikiparmar\n",
      "[2019-03-24 07:29:38,268] - Getting info for https://api.github.com/users/tfds-copybara\n",
      "[2019-03-24 07:29:39,966] - Getting info for https://api.github.com/users/googlebot\n",
      "[2019-03-24 07:29:51,227] - Getting info for https://api.github.com/users/andrewk1\n",
      "[2019-03-24 07:29:53,272] - Getting info for https://api.github.com/users/saldistefano\n",
      "[2019-03-24 07:29:57,463] - Getting info for https://api.github.com/users/jidroid404\n",
      "[2019-03-24 07:30:00,560] - Getting info for https://api.github.com/users/EduardoDixo\n",
      "[2019-03-24 07:30:04,455] - Getting info for https://api.github.com/users/yashk2810\n",
      "[2019-03-24 07:30:07,031] - Getting info for https://api.github.com/users/anandtrex\n",
      "[2019-03-24 07:30:10,784] - Getting info for https://api.github.com/users/galeone\n",
      "[2019-03-24 07:30:12,941] - Getting info for https://api.github.com/users/ShilpaSangappa\n",
      "[2019-03-24 07:30:14,036] - Getting info for https://api.github.com/users/Naio\n",
      "[2019-03-24 07:30:19,327] - Getting info for https://api.github.com/users/cuent\n",
      "[2019-03-24 07:30:21,443] - Getting info for https://api.github.com/users/vyraun\n",
      "[2019-03-24 07:30:22,467] - Getting info for https://api.github.com/users/nirum\n",
      "[2019-03-24 07:30:25,002] - Getting info for https://api.github.com/users/ChanchalKumarMaji\n",
      "[2019-03-24 07:30:26,164] - Getting info for https://api.github.com/users/mathetes87\n",
      "[2019-03-24 07:30:28,269] - Getting info for https://api.github.com/users/Rohith-hacker\n",
      "[2019-03-24 07:30:30,270] - Getting info for https://api.github.com/users/mrkaworu\n",
      "[2019-03-24 07:30:32,439] - Getting info for https://api.github.com/users/oscartackstrom\n",
      "[2019-03-24 07:30:33,432] - Getting info for https://api.github.com/users/georgedahl\n",
      "[2019-03-24 07:30:35,003] - Getting info for https://api.github.com/users/adikolsur\n",
      "[2019-03-24 07:30:36,495] - Getting info for https://api.github.com/users/doobwa\n",
      "[2019-03-24 07:30:37,400] - Getting info for https://api.github.com/users/kyscg\n",
      "[2019-03-24 07:30:39,492] - Getting info for https://api.github.com/users/drewszurko\n",
      "[2019-03-24 07:30:41,529] - Getting info for https://api.github.com/users/navneet-nmk\n",
      "[2019-03-24 07:30:43,075] - Getting info for https://api.github.com/users/yunpengli\n",
      "[2019-03-24 07:30:44,858] - Getting info for https://api.github.com/users/Anupam-tripathi\n",
      "[2019-03-24 07:30:45,804] - Getting info for https://api.github.com/users/sibyjackgrove\n",
      "[2019-03-24 07:30:46,840] - Getting info for https://api.github.com/users/dirkweissenborn\n",
      "[2019-03-24 07:30:48,777] - Getting info for https://api.github.com/users/rom1504\n",
      "[2019-03-24 07:30:53,001] - Getting info for https://api.github.com/users/ayush1999\n",
      "[2019-03-24 07:30:55,205] - Getting info for https://api.github.com/users/Shashankjain12\n",
      "[2019-03-24 07:30:57,801] - Getting info for https://api.github.com/users/gogasca\n",
      "[2019-03-24 07:31:01,134] - Getting info for https://api.github.com/users/Naman-Bhalla\n",
      "[2019-03-24 07:31:02,203] - Getting info for https://api.github.com/users/tabshaikh\n",
      "[2019-03-24 07:31:05,685] - Getting info for https://api.github.com/users/qianpeisheng\n",
      "[2019-03-24 07:31:07,043] - Getting info for https://api.github.com/users/usmanmuhd\n",
      "[2019-03-24 07:31:08,055] - Getting info for https://api.github.com/users/nahidalam\n",
      "[2019-03-24 07:31:09,573] - Getting info for https://api.github.com/users/KumarArindam\n",
      "[2019-03-24 07:31:14,725] - Getting info for https://api.github.com/users/ParthS007\n",
      "[2019-03-24 07:31:15,698] - Getting info for https://api.github.com/users/ctiijima\n",
      "[2019-03-24 07:31:19,568] - Getting info for https://api.github.com/users/vijaysinghkadam\n",
      "[2019-03-24 07:31:25,783] - Getting info for https://api.github.com/users/captain-pool\n",
      "[2019-03-24 07:31:28,374] - Getting info for https://api.github.com/users/aayu04\n",
      "[2019-03-24 07:31:31,225] - Getting info for https://api.github.com/users/theimgclist\n",
      "[2019-03-24 07:31:32,193] - Getting info for https://api.github.com/users/EszKnop\n",
      "[2019-03-24 07:31:33,235] - Getting info for https://api.github.com/users/us\n",
      "[2019-03-24 07:31:36,504] - Getting info for https://api.github.com/users/SoumyadeepJana\n",
      "[2019-03-24 07:31:38,043] - Getting info for https://api.github.com/users/AS2910\n",
      "[2019-03-24 07:31:40,085] - Getting info for https://api.github.com/users/gbpcosta\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-03-24 07:31:41,125] - Getting info for https://api.github.com/users/HanGuo97\n",
      "[2019-03-24 07:31:43,317] - Getting info for https://api.github.com/users/Ecalpal\n",
      "[2019-03-24 07:31:44,305] - Getting info for https://api.github.com/users/PulkitMishra\n",
      "[2019-03-24 07:31:48,161] - Getting info for https://api.github.com/users/zh794390558\n",
      "[2019-03-24 07:31:52,504] - Getting info for https://api.github.com/users/kaustumbh7\n",
      "[2019-03-24 07:31:54,305] - Getting info for https://api.github.com/users/pyaf\n",
      "[2019-03-24 07:31:56,474] - Getting info for https://api.github.com/users/joeyearsley\n",
      "[2019-03-24 07:31:57,497] - Getting info for https://api.github.com/users/vinsalg\n",
      "[2019-03-24 07:31:58,532] - Getting info for https://api.github.com/users/mtngld\n",
      "[2019-03-24 07:31:59,645] - Getting info for https://api.github.com/users/VIGS25\n",
      "[2019-03-24 07:32:00,660] - Getting info for https://api.github.com/users/AnthonyZhai\n",
      "[2019-03-24 07:32:01,684] - Getting info for https://api.github.com/users/Kammerlo\n",
      "[2019-03-24 07:32:02,697] - Getting info for https://api.github.com/users/dodiknikola\n",
      "[2019-03-24 07:32:03,721] - Getting info for https://api.github.com/users/jricheimer\n",
      "[2019-03-24 07:32:04,814] - Getting info for https://api.github.com/users/bonlime\n",
      "[2019-03-24 07:32:08,347] - Getting info for https://api.github.com/users/bileschi\n",
      "[2019-03-24 07:32:10,006] - Getting info for https://api.github.com/users/yongtang\n",
      "[2019-03-24 07:32:10,993] - Getting info for https://api.github.com/users/BryanCutler\n",
      "[2019-03-24 07:32:14,168] - Getting info for https://api.github.com/users/sknadig\n",
      "[2019-03-24 07:32:15,180] - Getting info for https://api.github.com/users/dbieber\n",
      "[2019-03-24 07:32:16,126] - Getting info for https://api.github.com/users/korakot\n",
      "[2019-03-24 07:32:18,399] - Getting info for https://api.github.com/users/natashafn\n",
      "[2019-03-24 07:32:19,399] - Getting info for https://api.github.com/users/danbri\n",
      "[2019-03-24 07:32:22,710] - Getting info for https://api.github.com/users/samuelmurray\n",
      "[2019-03-24 07:32:25,194] - Getting info for https://api.github.com/users/joel-shor\n",
      "[2019-03-24 07:32:29,328] - Getting info for https://api.github.com/users/zishanahmed08\n",
      "[2019-03-24 07:32:30,881] - Getting info for https://api.github.com/users/nikste\n",
      "[2019-03-24 07:32:32,484] - Getting info for https://api.github.com/users/maxfiedler\n",
      "[2019-03-24 07:32:33,555] - Getting info for https://api.github.com/users/dandelin\n",
      "[2019-03-24 07:32:35,603] - Getting info for https://api.github.com/users/razorx89\n",
      "[2019-03-24 07:32:36,606] - Getting info for https://api.github.com/users/SueMagic\n",
      "[2019-03-24 07:32:41,012] - Getting info for https://api.github.com/users/Jeetu95\n",
      "[2019-03-24 07:32:41,980] - Getting info for https://api.github.com/users/chuong98\n",
      "[2019-03-24 07:32:43,061] - Getting info for https://api.github.com/users/suvarna-kadam\n",
      "[2019-03-24 07:32:44,625] - Getting info for https://api.github.com/users/ubershmekel\n",
      "[2019-03-24 07:32:46,646] - Getting info for https://api.github.com/users/f1recracker\n",
      "[2019-03-24 07:32:48,740] - Getting info for https://api.github.com/users/StphMe\n",
      "[2019-03-24 07:32:49,724] - Getting info for https://api.github.com/users/alexalemi\n",
      "[2019-03-24 07:32:51,846] - Getting info for https://api.github.com/users/saipavan2405\n",
      "[2019-03-24 07:33:10,734] - Getting info for https://api.github.com/users/mostafaelhoushi\n",
      "[2019-03-24 07:33:12,715] - Getting info for https://api.github.com/users/drozzy\n",
      "[2019-03-24 07:33:17,569] - Getting info for https://api.github.com/users/remydubois\n",
      "[2019-03-24 07:33:21,815] - Getting info for https://api.github.com/users/apark263\n",
      "[2019-03-24 07:33:26,687] - Getting info for https://api.github.com/users/mandroid6\n",
      "[2019-03-24 07:33:30,460] - Getting info for https://api.github.com/users/review-notebook-app[bot]\n",
      "[2019-03-24 07:33:34,271] - Getting info for https://api.github.com/users/kmh4321\n",
      "[2019-03-24 07:33:37,459] - Getting info for https://api.github.com/users/prasadgujar\n",
      "[2019-03-24 07:33:40,763] - Getting info for https://api.github.com/users/Nimishkhurana\n",
      "[2019-03-24 07:33:44,504] - Getting info for https://api.github.com/users/MarcioPorto\n",
      "[2019-03-24 07:33:45,518] - Getting info for https://api.github.com/users/prathmesh36\n",
      "[2019-03-24 07:33:46,541] - Getting info for https://api.github.com/users/shaunVB\n",
      "[2019-03-24 07:33:47,521] - Getting info for https://api.github.com/users/ni3aswal\n",
      "[2019-03-24 07:33:48,590] - Getting info for https://api.github.com/users/audi187\n",
      "[2019-03-24 07:33:49,631] - Getting info for https://api.github.com/users/SinghKislay\n",
      "[2019-03-24 07:33:51,177] - Getting info for https://api.github.com/users/GeertLitjens\n",
      "[2019-03-24 07:33:54,759] - Getting info for https://api.github.com/users/adarob\n",
      "[2019-03-24 07:33:59,035] - Getting info for https://api.github.com/users/pmkalshetti\n",
      "[2019-03-24 07:34:00,621] - Getting info for https://api.github.com/users/InduManimaran\n",
      "[2019-03-24 07:34:02,109] - Getting info for https://api.github.com/users/iswariyam\n",
      "[2019-03-24 07:34:04,506] - Getting info for https://api.github.com/users/jihunchoi\n",
      "[2019-03-24 07:34:07,795] - Getting info for https://api.github.com/users/gmnvh\n",
      "[2019-03-24 07:34:10,013] - Getting info for https://api.github.com/users/cbentes\n",
      "[2019-03-24 07:34:14,700] - Getting info for https://api.github.com/users/normster\n",
      "[2019-03-24 07:34:16,282] - Getting info for https://api.github.com/users/alanpurple\n",
      "[2019-03-24 07:34:23,210] - Getting info for https://api.github.com/users/ageron\n",
      "[2019-03-24 07:34:26,516] - Getting info for https://api.github.com/users/EmanueleGhelfi\n",
      "[2019-03-24 07:34:28,576] - Getting info for https://api.github.com/users/GrtSid\n",
      "[2019-03-24 07:34:35,805] - Getting info for https://api.github.com/users/daniharsh28\n",
      "[2019-03-24 07:34:37,934] - Getting info for https://api.github.com/users/jsaurabh\n",
      "[2019-03-24 07:34:38,993] - Getting info for https://api.github.com/users/LawrenceXu13467\n",
      "[2019-03-24 07:34:58,867] - Getting info for https://api.github.com/users/amitness\n",
      "[2019-03-24 07:35:00,564] - Getting info for https://api.github.com/users/deemedkage\n",
      "[2019-03-24 07:35:01,509] - Getting info for https://api.github.com/users/Shashi456\n",
      "[2019-03-24 07:35:03,425] - Getting info for https://api.github.com/users/gshashank84\n",
      "[2019-03-24 07:35:05,742] - Getting info for https://api.github.com/users/sfujiwara\n",
      "[2019-03-24 07:35:10,599] - Getting info for https://api.github.com/users/ppham27\n",
      "[2019-03-24 07:35:11,818] - Getting info for https://api.github.com/users/karanchahal\n",
      "[2019-03-24 07:35:13,933] - Getting info for https://api.github.com/users/pembeci\n",
      "[2019-03-24 07:35:14,924] - Getting info for https://api.github.com/users/dogukanerel\n",
      "[2019-03-24 07:35:20,350] - Getting info for https://api.github.com/users/amanp592\n",
      "[2019-03-24 07:35:22,002] - Getting info for https://api.github.com/users/interactivetech\n",
      "[2019-03-24 07:35:22,939] - Getting info for https://api.github.com/users/akolesnikoff\n",
      "[2019-03-24 07:35:29,313] - Sir Perceval completed his quest.\n",
      "[2019-03-24 07:35:29,791] - Sir Perceval is on his quest.\n",
      "[2019-03-24 07:35:35,488] - Getting info for https://api.github.com/users/piyush-kgp\n",
      "[2019-03-24 07:35:37,966] - Getting info for https://api.github.com/users/brettkoonce\n",
      "[2019-03-24 07:35:38,951] - Getting info for https://api.github.com/users/rsepassi\n",
      "[2019-03-24 07:35:41,233] - Getting info for https://api.github.com/users/RicCu\n",
      "[2019-03-24 07:35:42,346] - Getting info for https://api.github.com/users/Conchylicultor\n",
      "[2019-03-24 07:35:44,795] - Getting info for https://api.github.com/users/lc0\n",
      "[2019-03-24 07:35:45,820] - Getting info for https://api.github.com/users/tfds-copybara\n",
      "[2019-03-24 07:35:48,292] - Getting info for https://api.github.com/users/jackd\n",
      "[2019-03-24 07:35:51,936] - Getting info for https://api.github.com/users/rodrigob\n",
      "[2019-03-24 07:35:54,331] - Getting info for https://api.github.com/users/lgeiger\n",
      "[2019-03-24 07:36:29,339] - Getting info for https://api.github.com/users/andrewk1\n",
      "[2019-03-24 07:36:41,315] - Getting info for https://api.github.com/users/jidroid404\n",
      "[2019-03-24 07:37:03,874] - Getting info for https://api.github.com/users/ChanchalKumarMaji\n",
      "[2019-03-24 07:37:07,768] - Getting info for https://api.github.com/users/kyscg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-03-24 07:37:16,341] - Getting info for https://api.github.com/users/drewszurko\n",
      "[2019-03-24 07:37:17,396] - Getting info for https://api.github.com/users/cyfra\n",
      "[2019-03-24 07:37:27,438] - Getting info for https://api.github.com/users/ayush1999\n",
      "[2019-03-24 07:37:33,358] - Getting info for https://api.github.com/users/KumarArindam\n",
      "[2019-03-24 07:37:39,937] - Getting info for https://api.github.com/users/ctiijima\n",
      "[2019-03-24 07:37:42,500] - Getting info for https://api.github.com/users/ParthS007\n",
      "[2019-03-24 07:37:50,269] - Getting info for https://api.github.com/users/captain-pool\n",
      "[2019-03-24 07:37:53,697] - Getting info for https://api.github.com/users/aayu04\n",
      "[2019-03-24 07:37:56,204] - Getting info for https://api.github.com/users/us\n",
      "[2019-03-24 07:38:18,595] - Getting info for https://api.github.com/users/AS2910\n",
      "[2019-03-24 07:38:24,125] - Getting info for https://api.github.com/users/ubershmekel\n",
      "[2019-03-24 07:38:41,617] - Getting info for https://api.github.com/users/Shashankjain12\n",
      "[2019-03-24 07:38:59,457] - Getting info for https://api.github.com/users/apark263\n",
      "[2019-03-24 07:39:02,184] - Getting info for https://api.github.com/users/kaustumbh7\n",
      "[2019-03-24 07:39:05,357] - Getting info for https://api.github.com/users/razorx89\n",
      "[2019-03-24 07:39:14,915] - Getting info for https://api.github.com/users/f1recracker\n",
      "[2019-03-24 07:39:27,768] - Getting info for https://api.github.com/users/GeertLitjens\n",
      "[2019-03-24 07:39:35,545] - Getting info for https://api.github.com/users/iswariyam\n",
      "[2019-03-24 07:39:38,157] - Getting info for https://api.github.com/users/SoumyadeepJana\n",
      "[2019-03-24 07:39:40,748] - Getting info for https://api.github.com/users/Rohith-hacker\n",
      "[2019-03-24 07:39:44,841] - Getting info for https://api.github.com/users/pmkalshetti\n",
      "[2019-03-24 07:40:15,345] - Getting info for https://api.github.com/users/ageron\n",
      "[2019-03-24 07:40:27,321] - Getting info for https://api.github.com/users/ptschandl\n",
      "[2019-03-24 07:40:42,183] - Getting info for https://api.github.com/users/suvarnak\n",
      "[2019-03-24 07:40:47,212] - Getting info for https://api.github.com/users/SinghKislay\n",
      "[2019-03-24 07:40:57,795] - Sir Perceval completed his quest.\n"
     ]
    }
   ],
   "source": [
    "!perceval git --json-line https://github.com/tensorflow/datasets > tf_analysis.json\n",
    "!perceval github -t $ACCESS_TOKEN --json-line --sleep-for-rate --category issue $owner $repo >> tf_analysis.json\n",
    "!perceval github -t $ACCESS_TOKEN --json-line --sleep-for-rate --category pull_request $owner $repo >> tf_analysis.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date and time of data retrieval :  2019-03-24 01:58:23 UTC \n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('tf_analysis.json') as f:\n",
    "    line = f.readline()\n",
    "    line = json.loads(line) #convert string to dict\n",
    "time = datetime.datetime.utcfromtimestamp(line['timestamp']).strftime('%Y-%m-%d %H:%M:%S UTC %Z%z')\n",
    "print ('The date and time of data retrieval : ',time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Code_Changes:\n",
    "    \"\"\"Class for Code_Changes for Git repositories.\n",
    "    \n",
    "    Objects are instantiated by specifying a file with the\n",
    "    commits obtained by Perceval from a set of repositories.\n",
    "        \n",
    "    :param path: Path to file with one Perceval JSON document per line\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _summary(repo, cdata):\n",
    "        \"\"\"Compute a summary of a commit, suitable as a row in a dataframe\"\"\"\n",
    "        \n",
    "        summary = {\n",
    "            'repo': repo,\n",
    "            'hash': cdata['commit'],\n",
    "            'author': cdata['Author'],\n",
    "            'author_date': datetime.datetime.strptime(cdata['AuthorDate'],\n",
    "                                                      \"%a %b %d %H:%M:%S %Y %z\"),\n",
    "            'commit': cdata['Commit'],\n",
    "            'commit_date': datetime.datetime.strptime(cdata['CommitDate'],\n",
    "                                                      \"%a %b %d %H:%M:%S %Y %z\"),\n",
    "            'files_no': len(cdata['files'])\n",
    "        }\n",
    "        actions = 0\n",
    "        for file in cdata['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "        summary['files_action'] = actions\n",
    "        if 'Merge' in cdata:\n",
    "            summary['merge'] = True\n",
    "        else:\n",
    "            summary['merge'] = False\n",
    "        return summary;\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"Initilizes self.df, the dataframe with one row per commit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = pd.DataFrame(columns=['hash', 'author', 'author_date',\n",
    "                                        'commit', 'commit_date',\n",
    "                                        'files_no', 'files_action',\n",
    "                                        'merge','repo'])\n",
    "        commits = []\n",
    "        with open(path) as commits_file:\n",
    "            for line in commits_file:\n",
    "                line = json.loads(line)\n",
    "                if(line['category']==\"commit\"):\n",
    "                    commit = line\n",
    "                    commits.append(self._summary(repo=commit['origin'],cdata=commit['data']))\n",
    "        \n",
    "        self.df = self.df.append(commits, sort=False)\n",
    "        self.df['author_date'] = pd.to_datetime(self.df['author_date'], utc=True)\n",
    "        self.df['commit_date'] = pd.to_datetime(self.df['commit_date'], utc=True)\n",
    "        \n",
    "    def total_count(self):\n",
    "        \n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def count(self, since = None, until = None, empty=True, merge=True, date='author_date'):\n",
    "        \"\"\"Count number of commits\n",
    "        \n",
    "        :param since: Period start\n",
    "        :param until: Period end\n",
    "        :param empty: Include empty commits\n",
    "        :param merge: Include merge commits\n",
    "        :param  date: Kind of date ('author_date' or 'commit_date')\n",
    "        \"\"\"\n",
    "        \n",
    "        df = self.df\n",
    "        if since:\n",
    "            df = df[df[date] >= since]\n",
    "        if until:\n",
    "            df = df[df[date] < until]\n",
    "        if not empty:\n",
    "            df = df[df['files_action'] != 0]\n",
    "        if not merge:\n",
    "            df = df[df['merge'] == False]\n",
    "        return df['hash'].nunique()\n",
    "    \n",
    "    def by_month(self):\n",
    "        \n",
    "        return self.df['author_date'] \\\n",
    "            .groupby([self.df.author_date.dt.year.rename('year'),\n",
    "                      self.df.author_date.dt.month.rename('month')]) \\\n",
    "            .agg('count')\n",
    "            \n",
    "    def unique_users(self):\n",
    "        return self.df.author.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code changes total count: 696\n",
      "Code changes count all period: 696\n",
      "Code changes count from 2018-09-12 to 2019-03-10: 617\n",
      "Code changes count from 2018-09-12 to 2019-03-10:(no merge commits): 600\n",
      "Code changes count from 2018-09-12 to 2019-03-10:(no empty commits): 614\n"
     ]
    }
   ],
   "source": [
    "changes = Code_Changes('tf_analysis.json')\n",
    "print(\"Code changes total count:\", changes.total_count())\n",
    "print(\"Code changes count all period:\", changes.count())\n",
    "print(\"Code changes count from 2018-09-12 to 2019-03-10:\",\n",
    "      changes.count(since=\"2018-09-12\", until=\"2019-03-10\"))\n",
    "print(\"Code changes count from 2018-09-12 to 2019-03-10:(no merge commits):\",\n",
    "      changes.count(since=\"2018-09-12\", until=\"2019-03-10\", merge=False))\n",
    "print(\"Code changes count from 2018-09-12 to 2019-03-10:(no empty commits):\",\n",
    "      changes.count(since=\"2018-09-12\", until=\"2019-03-10\", empty=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>author</th>\n",
       "      <th>author_date</th>\n",
       "      <th>commit</th>\n",
       "      <th>commit_date</th>\n",
       "      <th>files_no</th>\n",
       "      <th>files_action</th>\n",
       "      <th>merge</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680c6bda1b7d6db9d74f9c1373ebe737938926a7</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-12 21:23:17+00:00</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-12 21:23:17+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/tensorflow/datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87fd7f9fc4e36aa917726f3e8f89b7c89c99fb66</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-11 19:10:03+00:00</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-12 21:28:48+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/tensorflow/datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fb0f20383bb2a83477770517767b53ad97ec0840</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-12 20:12:22+00:00</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-12 21:28:57+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/tensorflow/datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca9ffcccb2ae3409c4210475b6407b871ad51ba9</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-13 19:53:54+00:00</td>\n",
       "      <td>Ryan Sepassi &lt;rsepassi@google.com&gt;</td>\n",
       "      <td>2018-09-13 19:59:39+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/tensorflow/datasets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3f650ac05ea4e5d1eeef55a9d3a70a75b1cb5843</td>\n",
       "      <td>Dustin Tran &lt;trandustin@google.com&gt;</td>\n",
       "      <td>2018-09-20 18:59:48+00:00</td>\n",
       "      <td>Copybara-Service &lt;copybara-piper@google.com&gt;</td>\n",
       "      <td>2018-09-21 23:28:12+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>https://github.com/tensorflow/datasets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hash  \\\n",
       "0  680c6bda1b7d6db9d74f9c1373ebe737938926a7   \n",
       "1  87fd7f9fc4e36aa917726f3e8f89b7c89c99fb66   \n",
       "2  fb0f20383bb2a83477770517767b53ad97ec0840   \n",
       "3  ca9ffcccb2ae3409c4210475b6407b871ad51ba9   \n",
       "4  3f650ac05ea4e5d1eeef55a9d3a70a75b1cb5843   \n",
       "\n",
       "                                author               author_date  \\\n",
       "0   Ryan Sepassi <rsepassi@google.com> 2018-09-12 21:23:17+00:00   \n",
       "1   Ryan Sepassi <rsepassi@google.com> 2018-09-11 19:10:03+00:00   \n",
       "2   Ryan Sepassi <rsepassi@google.com> 2018-09-12 20:12:22+00:00   \n",
       "3   Ryan Sepassi <rsepassi@google.com> 2018-09-13 19:53:54+00:00   \n",
       "4  Dustin Tran <trandustin@google.com> 2018-09-20 18:59:48+00:00   \n",
       "\n",
       "                                         commit               commit_date  \\\n",
       "0            Ryan Sepassi <rsepassi@google.com> 2018-09-12 21:23:17+00:00   \n",
       "1            Ryan Sepassi <rsepassi@google.com> 2018-09-12 21:28:48+00:00   \n",
       "2            Ryan Sepassi <rsepassi@google.com> 2018-09-12 21:28:57+00:00   \n",
       "3            Ryan Sepassi <rsepassi@google.com> 2018-09-13 19:59:39+00:00   \n",
       "4  Copybara-Service <copybara-piper@google.com> 2018-09-21 23:28:12+00:00   \n",
       "\n",
       "  files_no files_action  merge                                    repo  \n",
       "0        1            1  False  https://github.com/tensorflow/datasets  \n",
       "1       11           11  False  https://github.com/tensorflow/datasets  \n",
       "2        2            2  False  https://github.com/tensorflow/datasets  \n",
       "3        5            5  False  https://github.com/tensorflow/datasets  \n",
       "4        2            2  False  https://github.com/tensorflow/datasets  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year  month\n",
       "2018  9         10\n",
       "      10        28\n",
       "      11       107\n",
       "      12       137\n",
       "2019  1        122\n",
       "      2        148\n",
       "      3        144\n",
       "Name: author_date, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes.by_month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different identities :  42\n"
     ]
    }
   ],
   "source": [
    "print('Number of different identities : ',changes.unique_users()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Commits (master branch): 677\n"
     ]
    }
   ],
   "source": [
    "# Create a dict having all commits\n",
    "commits = {}\n",
    "with open('tf_analysis.json') as commits_file:\n",
    "    for line in commits_file:\n",
    "        line = json.loads(line)\n",
    "        if(line['category']==\"commit\"):\n",
    "            commit = line\n",
    "            commits[commit['data']['commit']] = commit\n",
    "            \n",
    "# Find commits in master branch.\n",
    "# Start by adding head to an empty todo list. Then loop until todo set is empty:\n",
    "# for each commit in the todo list, add it to the master set, and go backwards\n",
    "# (finding parents), adding them to the todo set.\n",
    "todo = set()\n",
    "for id, commit in commits.items():\n",
    "    if 'HEAD -> refs/heads/master' in commit['data']['refs']:\n",
    "        todo.add(id)\n",
    "\n",
    "        \n",
    "master = set()\n",
    "while len(todo) > 0:\n",
    "    current = todo.pop()\n",
    "    master.add(current)\n",
    "    for parent in commits[current]['data']['parents']:\n",
    "        if parent not in master:\n",
    "            todo.add(parent)\n",
    "    \n",
    "code_commits = len(master)\n",
    "    \n",
    "print(\"Code Commits (master branch):\", code_commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backend_name': 'GitHub',\n",
      " 'backend_version': '0.19.0',\n",
      " 'category': 'pull_request',\n",
      " 'data': {'_links': {'comments': {'href': 'https://api.github.com/repos/tensorflow/datasets/issues/3/comments'},\n",
      "                     'commits': {'href': 'https://api.github.com/repos/tensorflow/datasets/pulls/3/commits'},\n",
      "                     'html': {'href': 'https://github.com/tensorflow/datasets/pull/3'},\n",
      "                     'issue': {'href': 'https://api.github.com/repos/tensorflow/datasets/issues/3'},\n",
      "                     'review_comment': {'href': 'https://api.github.com/repos/tensorflow/datasets/pulls/comments{/number}'},\n",
      "                     'review_comments': {'href': 'https://api.github.com/repos/tensorflow/datasets/pulls/3/comments'},\n",
      "                     'self': {'href': 'https://api.github.com/repos/tensorflow/datasets/pulls/3'},\n",
      "                     'statuses': {'href': 'https://api.github.com/repos/tensorflow/datasets/statuses/40be02c39c6b52d6427710012720f7150cadeadb'}},\n",
      "          'additions': 28,\n",
      "          'assignee': None,\n",
      "          'assignees': [],\n",
      "          'author_association': 'NONE',\n",
      "          'base': {'label': 'tensorflow:master',\n",
      "                   'ref': 'master',\n",
      "                   'repo': {'archive_url': 'https://api.github.com/repos/tensorflow/datasets/{archive_format}{/ref}',\n",
      "                            'archived': False,\n",
      "                            'assignees_url': 'https://api.github.com/repos/tensorflow/datasets/assignees{/user}',\n",
      "                            'blobs_url': 'https://api.github.com/repos/tensorflow/datasets/git/blobs{/sha}',\n",
      "                            'branches_url': 'https://api.github.com/repos/tensorflow/datasets/branches{/branch}',\n",
      "                            'clone_url': 'https://github.com/tensorflow/datasets.git',\n",
      "                            'collaborators_url': 'https://api.github.com/repos/tensorflow/datasets/collaborators{/collaborator}',\n",
      "                            'comments_url': 'https://api.github.com/repos/tensorflow/datasets/comments{/number}',\n",
      "                            'commits_url': 'https://api.github.com/repos/tensorflow/datasets/commits{/sha}',\n",
      "                            'compare_url': 'https://api.github.com/repos/tensorflow/datasets/compare/{base}...{head}',\n",
      "                            'contents_url': 'https://api.github.com/repos/tensorflow/datasets/contents/{+path}',\n",
      "                            'contributors_url': 'https://api.github.com/repos/tensorflow/datasets/contributors',\n",
      "                            'created_at': '2018-09-10T21:27:22Z',\n",
      "                            'default_branch': 'master',\n",
      "                            'deployments_url': 'https://api.github.com/repos/tensorflow/datasets/deployments',\n",
      "                            'description': 'A collection of datasets ready to '\n",
      "                                           'use with TensorFlow',\n",
      "                            'downloads_url': 'https://api.github.com/repos/tensorflow/datasets/downloads',\n",
      "                            'events_url': 'https://api.github.com/repos/tensorflow/datasets/events',\n",
      "                            'fork': False,\n",
      "                            'forks': 158,\n",
      "                            'forks_count': 158,\n",
      "                            'forks_url': 'https://api.github.com/repos/tensorflow/datasets/forks',\n",
      "                            'full_name': 'tensorflow/datasets',\n",
      "                            'git_commits_url': 'https://api.github.com/repos/tensorflow/datasets/git/commits{/sha}',\n",
      "                            'git_refs_url': 'https://api.github.com/repos/tensorflow/datasets/git/refs{/sha}',\n",
      "                            'git_tags_url': 'https://api.github.com/repos/tensorflow/datasets/git/tags{/sha}',\n",
      "                            'git_url': 'git://github.com/tensorflow/datasets.git',\n",
      "                            'has_downloads': True,\n",
      "                            'has_issues': True,\n",
      "                            'has_pages': False,\n",
      "                            'has_projects': False,\n",
      "                            'has_wiki': False,\n",
      "                            'homepage': None,\n",
      "                            'hooks_url': 'https://api.github.com/repos/tensorflow/datasets/hooks',\n",
      "                            'html_url': 'https://github.com/tensorflow/datasets',\n",
      "                            'id': 148221325,\n",
      "                            'issue_comment_url': 'https://api.github.com/repos/tensorflow/datasets/issues/comments{/number}',\n",
      "                            'issue_events_url': 'https://api.github.com/repos/tensorflow/datasets/issues/events{/number}',\n",
      "                            'issues_url': 'https://api.github.com/repos/tensorflow/datasets/issues{/number}',\n",
      "                            'keys_url': 'https://api.github.com/repos/tensorflow/datasets/keys{/key_id}',\n",
      "                            'labels_url': 'https://api.github.com/repos/tensorflow/datasets/labels{/name}',\n",
      "                            'language': 'Python',\n",
      "                            'languages_url': 'https://api.github.com/repos/tensorflow/datasets/languages',\n",
      "                            'license': {'key': 'apache-2.0',\n",
      "                                        'name': 'Apache License 2.0',\n",
      "                                        'node_id': 'MDc6TGljZW5zZTI=',\n",
      "                                        'spdx_id': 'Apache-2.0',\n",
      "                                        'url': 'https://api.github.com/licenses/apache-2.0'},\n",
      "                            'merges_url': 'https://api.github.com/repos/tensorflow/datasets/merges',\n",
      "                            'milestones_url': 'https://api.github.com/repos/tensorflow/datasets/milestones{/number}',\n",
      "                            'mirror_url': None,\n",
      "                            'name': 'datasets',\n",
      "                            'node_id': 'MDEwOlJlcG9zaXRvcnkxNDgyMjEzMjU=',\n",
      "                            'notifications_url': 'https://api.github.com/repos/tensorflow/datasets/notifications{?since,all,participating}',\n",
      "                            'open_issues': 152,\n",
      "                            'open_issues_count': 152,\n",
      "                            'owner': {'avatar_url': 'https://avatars1.githubusercontent.com/u/15658638?v=4',\n",
      "                                      'events_url': 'https://api.github.com/users/tensorflow/events{/privacy}',\n",
      "                                      'followers_url': 'https://api.github.com/users/tensorflow/followers',\n",
      "                                      'following_url': 'https://api.github.com/users/tensorflow/following{/other_user}',\n",
      "                                      'gists_url': 'https://api.github.com/users/tensorflow/gists{/gist_id}',\n",
      "                                      'gravatar_id': '',\n",
      "                                      'html_url': 'https://github.com/tensorflow',\n",
      "                                      'id': 15658638,\n",
      "                                      'login': 'tensorflow',\n",
      "                                      'node_id': 'MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4',\n",
      "                                      'organizations_url': 'https://api.github.com/users/tensorflow/orgs',\n",
      "                                      'received_events_url': 'https://api.github.com/users/tensorflow/received_events',\n",
      "                                      'repos_url': 'https://api.github.com/users/tensorflow/repos',\n",
      "                                      'site_admin': False,\n",
      "                                      'starred_url': 'https://api.github.com/users/tensorflow/starred{/owner}{/repo}',\n",
      "                                      'subscriptions_url': 'https://api.github.com/users/tensorflow/subscriptions',\n",
      "                                      'type': 'Organization',\n",
      "                                      'url': 'https://api.github.com/users/tensorflow'},\n",
      "                            'private': False,\n",
      "                            'pulls_url': 'https://api.github.com/repos/tensorflow/datasets/pulls{/number}',\n",
      "                            'pushed_at': '2019-03-23T22:55:53Z',\n",
      "                            'releases_url': 'https://api.github.com/repos/tensorflow/datasets/releases{/id}',\n",
      "                            'size': 12106,\n",
      "                            'ssh_url': 'git@github.com:tensorflow/datasets.git',\n",
      "                            'stargazers_count': 960,\n",
      "                            'stargazers_url': 'https://api.github.com/repos/tensorflow/datasets/stargazers',\n",
      "                            'statuses_url': 'https://api.github.com/repos/tensorflow/datasets/statuses/{sha}',\n",
      "                            'subscribers_url': 'https://api.github.com/repos/tensorflow/datasets/subscribers',\n",
      "                            'subscription_url': 'https://api.github.com/repos/tensorflow/datasets/subscription',\n",
      "                            'svn_url': 'https://github.com/tensorflow/datasets',\n",
      "                            'tags_url': 'https://api.github.com/repos/tensorflow/datasets/tags',\n",
      "                            'teams_url': 'https://api.github.com/repos/tensorflow/datasets/teams',\n",
      "                            'trees_url': 'https://api.github.com/repos/tensorflow/datasets/git/trees{/sha}',\n",
      "                            'updated_at': '2019-03-23T22:09:20Z',\n",
      "                            'url': 'https://api.github.com/repos/tensorflow/datasets',\n",
      "                            'watchers': 960,\n",
      "                            'watchers_count': 960},\n",
      "                   'sha': 'ca9ffcccb2ae3409c4210475b6407b871ad51ba9',\n",
      "                   'user': {'avatar_url': 'https://avatars1.githubusercontent.com/u/15658638?v=4',\n",
      "                            'events_url': 'https://api.github.com/users/tensorflow/events{/privacy}',\n",
      "                            'followers_url': 'https://api.github.com/users/tensorflow/followers',\n",
      "                            'following_url': 'https://api.github.com/users/tensorflow/following{/other_user}',\n",
      "                            'gists_url': 'https://api.github.com/users/tensorflow/gists{/gist_id}',\n",
      "                            'gravatar_id': '',\n",
      "                            'html_url': 'https://github.com/tensorflow',\n",
      "                            'id': 15658638,\n",
      "                            'login': 'tensorflow',\n",
      "                            'node_id': 'MDEyOk9yZ2FuaXphdGlvbjE1NjU4NjM4',\n",
      "                            'organizations_url': 'https://api.github.com/users/tensorflow/orgs',\n",
      "                            'received_events_url': 'https://api.github.com/users/tensorflow/received_events',\n",
      "                            'repos_url': 'https://api.github.com/users/tensorflow/repos',\n",
      "                            'site_admin': False,\n",
      "                            'starred_url': 'https://api.github.com/users/tensorflow/starred{/owner}{/repo}',\n",
      "                            'subscriptions_url': 'https://api.github.com/users/tensorflow/subscriptions',\n",
      "                            'type': 'Organization',\n",
      "                            'url': 'https://api.github.com/users/tensorflow'}},\n",
      "          'body': 'The function is still unimplemented but at least the '\n",
      "                  'required files are there in the library and raises a decent '\n",
      "                  \"NotImplementedError rather than the ugly 'attribute not \"\n",
      "                  \"found'\\r\\n\"\n",
      "                  'Suggestions welcome.',\n",
      "          'changed_files': 3,\n",
      "          'closed_at': '2018-09-17T21:56:03Z',\n",
      "          'comments': 1,\n",
      "          'comments_url': 'https://api.github.com/repos/tensorflow/datasets/issues/3/comments',\n",
      "          'commits': 2,\n",
      "          'commits_data': ['44662dcb0b0c0a5ad09d58e51d34a181fcc47136',\n",
      "                           '40be02c39c6b52d6427710012720f7150cadeadb'],\n",
      "          'commits_url': 'https://api.github.com/repos/tensorflow/datasets/pulls/3/commits',\n",
      "          'created_at': '2018-09-17T19:57:28Z',\n",
      "          'deletions': 1,\n",
      "          'diff_url': 'https://github.com/tensorflow/datasets/pull/3.diff',\n",
      "          'head': {'label': 'piyush-kgp:fix-bug',\n",
      "                   'ref': 'fix-bug',\n",
      "                   'repo': None,\n",
      "                   'sha': '40be02c39c6b52d6427710012720f7150cadeadb',\n",
      "                   'user': {'avatar_url': 'https://avatars3.githubusercontent.com/u/19518507?v=4',\n",
      "                            'events_url': 'https://api.github.com/users/piyush-kgp/events{/privacy}',\n",
      "                            'followers_url': 'https://api.github.com/users/piyush-kgp/followers',\n",
      "                            'following_url': 'https://api.github.com/users/piyush-kgp/following{/other_user}',\n",
      "                            'gists_url': 'https://api.github.com/users/piyush-kgp/gists{/gist_id}',\n",
      "                            'gravatar_id': '',\n",
      "                            'html_url': 'https://github.com/piyush-kgp',\n",
      "                            'id': 19518507,\n",
      "                            'login': 'piyush-kgp',\n",
      "                            'node_id': 'MDQ6VXNlcjE5NTE4NTA3',\n",
      "                            'organizations_url': 'https://api.github.com/users/piyush-kgp/orgs',\n",
      "                            'received_events_url': 'https://api.github.com/users/piyush-kgp/received_events',\n",
      "                            'repos_url': 'https://api.github.com/users/piyush-kgp/repos',\n",
      "                            'site_admin': False,\n",
      "                            'starred_url': 'https://api.github.com/users/piyush-kgp/starred{/owner}{/repo}',\n",
      "                            'subscriptions_url': 'https://api.github.com/users/piyush-kgp/subscriptions',\n",
      "                            'type': 'User',\n",
      "                            'url': 'https://api.github.com/users/piyush-kgp'}},\n",
      "          'html_url': 'https://github.com/tensorflow/datasets/pull/3',\n",
      "          'id': 216096636,\n",
      "          'issue_url': 'https://api.github.com/repos/tensorflow/datasets/issues/3',\n",
      "          'labels': [],\n",
      "          'locked': False,\n",
      "          'maintainer_can_modify': False,\n",
      "          'merge_commit_sha': '8de97c108b74cbe042786b15cee9d5633eac2eaf',\n",
      "          'mergeable': None,\n",
      "          'mergeable_state': 'unknown',\n",
      "          'merged': False,\n",
      "          'merged_at': None,\n",
      "          'merged_by': None,\n",
      "          'merged_by_data': [],\n",
      "          'milestone': None,\n",
      "          'node_id': 'MDExOlB1bGxSZXF1ZXN0MjE2MDk2NjM2',\n",
      "          'number': 3,\n",
      "          'patch_url': 'https://github.com/tensorflow/datasets/pull/3.patch',\n",
      "          'rebaseable': None,\n",
      "          'requested_reviewers': [],\n",
      "          'requested_reviewers_data': [],\n",
      "          'requested_teams': [],\n",
      "          'review_comment_url': 'https://api.github.com/repos/tensorflow/datasets/pulls/comments{/number}',\n",
      "          'review_comments': 0,\n",
      "          'review_comments_data': {},\n",
      "          'review_comments_url': 'https://api.github.com/repos/tensorflow/datasets/pulls/3/comments',\n",
      "          'state': 'closed',\n",
      "          'statuses_url': 'https://api.github.com/repos/tensorflow/datasets/statuses/40be02c39c6b52d6427710012720f7150cadeadb',\n",
      "          'title': 'Fixes bug - datasets.load was not implemented',\n",
      "          'updated_at': '2018-09-29T12:17:13Z',\n",
      "          'url': 'https://api.github.com/repos/tensorflow/datasets/pulls/3',\n",
      "          'user': {'avatar_url': 'https://avatars3.githubusercontent.com/u/19518507?v=4',\n",
      "                   'events_url': 'https://api.github.com/users/piyush-kgp/events{/privacy}',\n",
      "                   'followers_url': 'https://api.github.com/users/piyush-kgp/followers',\n",
      "                   'following_url': 'https://api.github.com/users/piyush-kgp/following{/other_user}',\n",
      "                   'gists_url': 'https://api.github.com/users/piyush-kgp/gists{/gist_id}',\n",
      "                   'gravatar_id': '',\n",
      "                   'html_url': 'https://github.com/piyush-kgp',\n",
      "                   'id': 19518507,\n",
      "                   'login': 'piyush-kgp',\n",
      "                   'node_id': 'MDQ6VXNlcjE5NTE4NTA3',\n",
      "                   'organizations_url': 'https://api.github.com/users/piyush-kgp/orgs',\n",
      "                   'received_events_url': 'https://api.github.com/users/piyush-kgp/received_events',\n",
      "                   'repos_url': 'https://api.github.com/users/piyush-kgp/repos',\n",
      "                   'site_admin': False,\n",
      "                   'starred_url': 'https://api.github.com/users/piyush-kgp/starred{/owner}{/repo}',\n",
      "                   'subscriptions_url': 'https://api.github.com/users/piyush-kgp/subscriptions',\n",
      "                   'type': 'User',\n",
      "                   'url': 'https://api.github.com/users/piyush-kgp'},\n",
      "          'user_data': {'avatar_url': 'https://avatars3.githubusercontent.com/u/19518507?v=4',\n",
      "                        'bio': 'Machine Learning Engineer',\n",
      "                        'blog': '',\n",
      "                        'company': None,\n",
      "                        'created_at': '2016-05-22T15:54:20Z',\n",
      "                        'email': 'piyushsinghkgpian@gmail.com',\n",
      "                        'events_url': 'https://api.github.com/users/piyush-kgp/events{/privacy}',\n",
      "                        'followers': 13,\n",
      "                        'followers_url': 'https://api.github.com/users/piyush-kgp/followers',\n",
      "                        'following': 79,\n",
      "                        'following_url': 'https://api.github.com/users/piyush-kgp/following{/other_user}',\n",
      "                        'gists_url': 'https://api.github.com/users/piyush-kgp/gists{/gist_id}',\n",
      "                        'gravatar_id': '',\n",
      "                        'hireable': True,\n",
      "                        'html_url': 'https://github.com/piyush-kgp',\n",
      "                        'id': 19518507,\n",
      "                        'location': 'Mumbai, India',\n",
      "                        'login': 'piyush-kgp',\n",
      "                        'name': 'Piyush Singh',\n",
      "                        'node_id': 'MDQ6VXNlcjE5NTE4NTA3',\n",
      "                        'organizations': [],\n",
      "                        'organizations_url': 'https://api.github.com/users/piyush-kgp/orgs',\n",
      "                        'public_gists': 1,\n",
      "                        'public_repos': 57,\n",
      "                        'received_events_url': 'https://api.github.com/users/piyush-kgp/received_events',\n",
      "                        'repos_url': 'https://api.github.com/users/piyush-kgp/repos',\n",
      "                        'site_admin': False,\n",
      "                        'starred_url': 'https://api.github.com/users/piyush-kgp/starred{/owner}{/repo}',\n",
      "                        'subscriptions_url': 'https://api.github.com/users/piyush-kgp/subscriptions',\n",
      "                        'type': 'User',\n",
      "                        'updated_at': '2019-03-17T13:20:23Z',\n",
      "                        'url': 'https://api.github.com/users/piyush-kgp'}},\n",
      " 'origin': 'https://github.com/tensorflow/datasets',\n",
      " 'perceval_version': '0.12.7',\n",
      " 'tag': 'https://github.com/tensorflow/datasets',\n",
      " 'timestamp': 1553393137.190736,\n",
      " 'updated_on': 1538223433.0,\n",
      " 'uuid': '75da7312b7bb71088bae735a476139b73882ed69'}\n"
     ]
    }
   ],
   "source": [
    "with open('./tf_analysis.json') as pr_file:\n",
    "            for line in pr_file:\n",
    "                line = json.loads(line)\n",
    "                if(line['category']==\"pull_request\"):\n",
    "                    pr = line\n",
    "                    break\n",
    "pprint(pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pr_statistics:\n",
    "    \n",
    "    @staticmethod\n",
    "    def _summary(pr_data):\n",
    "        \"\"\"Compute a summary of a pull_request, suitable as a row in a dataframe\"\"\"\n",
    "        \n",
    "        summary = {\n",
    "            'base_repo': pr_data['base']['label'],\n",
    "            'title': pr_data['title'],\n",
    "            'state': pr_data['state'],\n",
    "            'commits':pr_data['commits'],\n",
    "            'commits_data': pr_data['commits_data'],\n",
    "            'comments':pr_data['comments'],\n",
    "            'changed_files': pr_data['changed_files'],\n",
    "            'additions': pr_data['additions'],\n",
    "            'deletions': pr_data['deletions'],\n",
    "            'created_at': pr_data['created_at'],\n",
    "            'closed_at': pr_data['closed_at'],\n",
    "            'user': pr_data['user_data']['login']\n",
    "        }\n",
    "        if (pr_data['merged']):\n",
    "            summary['merged_at'] = pr_data['merged_at']\n",
    "        else:\n",
    "            summary['merged_at'] = None\n",
    "        return summary;\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "           Initilizes self.df, the dataframe with one row per pull_request.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = pd.DataFrame(columns=['base_repo','title', 'state', 'commits', 'commits_data',\n",
    "                                        'comments', 'changed_files', 'additions', 'deletions', 'created_at'\n",
    "                                        'closed_at','user', 'merged_at'])\n",
    "        pull_requests= []\n",
    "        with open(path) as pr_file:\n",
    "            for line in pr_file:\n",
    "                line = json.loads(line)\n",
    "                if(line['category']==\"pull_request\"):\n",
    "                    pr = line\n",
    "                    pull_requests.append(self._summary(pr_data=pr['data']))\n",
    "\n",
    "        self.df = self.df.append(pull_requests, sort=False)\n",
    "        #self.df['author_date'] = pd.to_datetime(self.df['author_date'], utc=True)\n",
    "        #self.df['commit_date'] = pd.to_datetime(self.df['commit_date'], utc=True)\n",
    "        \n",
    "    def total_count(self):\n",
    "        \n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def open_prs(self):\n",
    "        return len(self.df.index[self.df['state']=='open'])\n",
    "    \n",
    "    def closed_prs(self):\n",
    "        return len(self.df.index[self.df['state']=='closed'])\n",
    "    \n",
    "    def unique_users(self):\n",
    "        return self.df.user.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of open prs 60\n",
      "Number of closed prs 117\n",
      "Number of unique users 36\n"
     ]
    }
   ],
   "source": [
    "pull_reqs = pr_statistics('./tf_analysis.json')\n",
    "print('Number of open prs', pull_reqs.open_prs())\n",
    "print('Number of closed prs', pull_reqs.closed_prs())\n",
    "print('Number of unique users', pull_reqs.unique_users())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tf_analysis.json') as issue_file:\n",
    "            for line in issue_file:\n",
    "                line = json.loads(line)\n",
    "                if(line['category']==\"issue\"):\n",
    "                    issue = line\n",
    "                    break\n",
    "pprint(issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class issue_statistics:\n",
    "    \n",
    "    @staticmethod\n",
    "    def _summary(issue_data):\n",
    "        \"\"\"Compute a summary of a pull_request, suitable as a row in a dataframe\"\"\"\n",
    "        \n",
    "        summary = {\n",
    "            'title': issue_data['title'],\n",
    "            'state': issue_data['state'],\n",
    "            'comments':issue_data['comments'],\n",
    "            'created_at': issue_data['created_at'],\n",
    "            'closed_at': issue_data['closed_at'],\n",
    "            'created_by': issue_data['user_data']['login']\n",
    "        }\n",
    "        return summary;\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "           Initilizes self.df, the dataframe with one row per issue.\n",
    "        \"\"\"\n",
    "\n",
    "        self.df = pd.DataFrame(columns=['title', 'state', 'created_at', 'closed_at', 'comments', 'created_by'])\n",
    "        issues = []\n",
    "        with open(path) as issue_file:\n",
    "            for line in issue_file:\n",
    "                line = json.loads(line)\n",
    "                if(line['category']==\"issue\"):\n",
    "                    issue = line\n",
    "                    issues.append(self._summary(issue_data=issue['data']))\n",
    "\n",
    "        self.df = self.df.append(issues, sort=False)\n",
    "        #self.df['author_date'] = pd.to_datetime(self.df['author_date'], utc=True)\n",
    "        #self.df['commit_date'] = pd.to_datetime(self.df['commit_date'], utc=True)\n",
    "        \n",
    "    def total_count(self):        \n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def open_issues(self):\n",
    "        return len(self.df.index[self.df['state']=='open'])\n",
    "    \n",
    "    def closed_issues(self):\n",
    "        return len(self.df.index[self.df['state']=='closed'])\n",
    "    \n",
    "    def unique_users(self):\n",
    "        return self.df.created_by.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of open issues 152\n",
      "Number of closed issues 171\n",
      "Number of unique issue creators 80\n"
     ]
    }
   ],
   "source": [
    "issues = issue_statistics('./tf_analysis.json'\n",
    "                         )\n",
    "print('Number of open issues', issues.open_issues())\n",
    "print('Number of closed issues', issues.closed_issues())\n",
    "print('Number of unique issue creators', issues.unique_users())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Example in README not working</td>\n",
       "      <td>closed</td>\n",
       "      <td>2018-09-17T18:42:13Z</td>\n",
       "      <td>2018-09-17T21:56:55Z</td>\n",
       "      <td>2</td>\n",
       "      <td>piyush-kgp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fixes bug - datasets.load was not implemented</td>\n",
       "      <td>closed</td>\n",
       "      <td>2018-09-17T19:57:28Z</td>\n",
       "      <td>2018-09-17T21:56:03Z</td>\n",
       "      <td>1</td>\n",
       "      <td>piyush-kgp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>error on pip install</td>\n",
       "      <td>closed</td>\n",
       "      <td>2018-09-26T12:32:21Z</td>\n",
       "      <td>2018-10-01T07:16:31Z</td>\n",
       "      <td>1</td>\n",
       "      <td>tiaguinho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Import error on Windows</td>\n",
       "      <td>closed</td>\n",
       "      <td>2018-09-14T10:09:00Z</td>\n",
       "      <td>2018-10-01T07:17:00Z</td>\n",
       "      <td>3</td>\n",
       "      <td>LoSealL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Question] - Would it be okay to generate tfre...</td>\n",
       "      <td>closed</td>\n",
       "      <td>2018-11-28T19:33:58Z</td>\n",
       "      <td>2018-11-29T19:11:58Z</td>\n",
       "      <td>1</td>\n",
       "      <td>ksachdeva</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title   state  \\\n",
       "0                      Example in README not working  closed   \n",
       "1      Fixes bug - datasets.load was not implemented  closed   \n",
       "2                               error on pip install  closed   \n",
       "3                            Import error on Windows  closed   \n",
       "4  [Question] - Would it be okay to generate tfre...  closed   \n",
       "\n",
       "             created_at             closed_at comments  created_by  \n",
       "0  2018-09-17T18:42:13Z  2018-09-17T21:56:55Z        2  piyush-kgp  \n",
       "1  2018-09-17T19:57:28Z  2018-09-17T21:56:03Z        1  piyush-kgp  \n",
       "2  2018-09-26T12:32:21Z  2018-10-01T07:16:31Z        1   tiaguinho  \n",
       "3  2018-09-14T10:09:00Z  2018-10-01T07:17:00Z        3     LoSealL  \n",
       "4  2018-11-28T19:33:58Z  2018-11-29T19:11:58Z        1   ksachdeva  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
