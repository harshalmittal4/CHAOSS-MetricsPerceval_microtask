{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask1\n",
    ">Microtask 1: Produce a notebook showing (and producing) a list with the activity per quarter: number of new committers, submitters of issues, and submitters of pull/merge requests, number of items (commits, issues, pull/merge requests), number of repositories with new items (all of this per quarter) as a table and as a CSV file. Use plain Python3 (eg, no Pandas) for this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarters\n",
    "The quarters are defined using the following dictionary where the **key corresponds to the month** and **value corresponds to the quarter**  :\n",
    "```\n",
    "quarter={1:'Q1', 2:'Q1', 3:'Q1', 4:'Q2', 5:'Q2', 6:'Q2', 7:'Q3', 8:'Q3', 9:'Q3', 10:'Q4', 11:'Q4', 12:'Q4'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime \n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from tabulate import tabulate\n",
    "import requests\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start and end year for the analysis\n",
    "The startyear and endyear for a repository are obtained from the Github API using the [requests].(http://www.python-requests.org/en/latest/)\n",
    "module\n",
    "- startyear : year of repository creation.\n",
    "- endyear : when the repository was last updated.\n",
    "\n",
    "The steps are :\n",
    "1. Call the API\n",
    "1. Assuming the API returns a JSON, parse the JSON object into a Python dict using json.loads function\n",
    "1. Loop through the dict to extract information.\n",
    "\n",
    "`if(Response.ok)`: will help help you determine if your API call is successful (Response code - 200)\n",
    "\n",
    "`Response.raise_for_status()` will help you fetch the http code that is returned from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api.github.com/repos/tensorflow/datasets' # url of repo to be analysed\n",
    "info = requests.get(url)\n",
    "if(info.ok):\n",
    "    startyear = datetime.strptime(json.loads(info.text)['created_at'], \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "    endyear = datetime.strptime(json.loads(info.text)['updated_at'], \"%Y-%m-%dT%H:%M:%SZ\").year\n",
    "else : \n",
    "    info.raise_for_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dictionary mapping months to quarters, and a list **indexes** which is as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for year in range(startyear, endyear+1):\n",
    "    for quarter in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        indexes.append(str(year) + '_' + quarter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018_Q1', '2018_Q2', '2018_Q3', '2018_Q4', '2019_Q1', '2019_Q2', '2019_Q3', '2019_Q4']\n"
     ]
    }
   ],
   "source": [
    "print(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionaries, and sets to get activity per quarter\n",
    "Suppose we have an item of category \"commit\":<br>\n",
    "Get the quarter(or index) for that commit(eg : '2018_Q3') using its date. Using that quarter(or index) as the key:<br>\n",
    "- Increment the value of commits_count[key].\n",
    "- Add the author of that commit to the set commiters_new[key].\n",
    "\n",
    "This is done for each item (commit, issue or pull_request) in the jsonfile,\n",
    "and the dictionaries are updated. We will print them below to get exactly what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_count = {}\n",
    "issue_count = {}\n",
    "pr_count = {}\n",
    "\n",
    "commiters_new = defaultdict(set)\n",
    "iss_creators_new = defaultdict(set)\n",
    "pr_senders_new = defaultdict(set)\n",
    "\n",
    "# indexes : ['2018_Q1', '2018_Q2', '2018_Q3', '2018_Q4', '2019_Q1', '2019_Q2', '2019_Q3', '2019_Q4']\n",
    "for key in indexes:         \n",
    "        commits_count[key] = 0\n",
    "        issue_count[key] = 0\n",
    "        pr_count [key] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get information from json and populate the dictionary fileds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary mapping month to quarter\n",
    "quarter={1:'Q1', 2:'Q1', 3:'Q1', 4:'Q2', 5:'Q2', 6:'Q2', 7:'Q3', 8:'Q3', 9:'Q3', 10:'Q4', 11:'Q4', 12:'Q4'}\n",
    "\n",
    "# function to get information from json and populate the dictionary fileds \n",
    "def analyse(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line)\n",
    "            if (line['category']=='commit'):\n",
    "                date = datetime.strptime(line['data']['CommitDate'],\"%a %b %d %H:%M:%S %Y %z\")\n",
    "                year = date.year\n",
    "                month = date.month\n",
    "                key = str(year) + \"_\" + quarter[month]\n",
    "                commits_count[key]+= 1\n",
    "                commiters_new[key].add(line['data']['Author'])\n",
    "\n",
    "            elif(line['category']=='issue'):\n",
    "                date = datetime.strptime(line['data']['created_at'],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                year = date.year\n",
    "                month = date.month\n",
    "                key = str(year) + '_' + quarter[month]\n",
    "                issue_count[key]+=1\n",
    "                iss_creators_new[key].add(line['data']['user_data']['login'])\n",
    "\n",
    "            else:\n",
    "                date = datetime.strptime(line['data']['created_at'],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                year = date.year\n",
    "                month = date.month\n",
    "                key = str(year) + '_' + quarter[month]\n",
    "                pr_count[key]+=1\n",
    "                pr_senders_new[key].add(line['data']['user_data']['login'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the analyse function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./tf_analysis.json\"\n",
    "analyse(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the commiters in each quarter (or index) to contain only new contributors\n",
    "This is done by creating a overall set of contributors for each category which is initialized by the contributors in the initial quarter and then updated by each quarter.<br>\n",
    "<br>\n",
    "For each subsequent quarter,\n",
    "1. commiters_new[quarter(or index)] set would be updated by removing elements of the old_commiters set(all commmiters till now) from it (if present), and\n",
    "1. the old_commiters set would be updated by adding commiters_new[quarter(or index)] to it if not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_count = len(indexes)\n",
    "old_commiters = commiters_new[0]\n",
    "old_pr_senders = pr_senders_new[0]\n",
    "old_iss_creators = iss_creators_new[0]\n",
    "\n",
    "for i in range (1, quarter_count):\n",
    "    commiters_new[indexes[i]] = commiters_new[indexes[i]].difference(old_commiters)\n",
    "    iss_creators_new[indexes[i]] = iss_creators_new[indexes[i]].difference(old_iss_creators)\n",
    "    pr_senders_new[indexes[i]] = pr_senders_new[indexes[i]].difference(old_pr_senders)\n",
    "    old_commiters.update(commiters_new[indexes[i]])\n",
    "    old_pr_senders.update(pr_senders_new[indexes[i]])\n",
    "    old_iss_creators.update(iss_creators_new[indexes[i]])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the dictionaries created above for commits - commiters_new and commits_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>,\n",
      "            {0: {'Adam Roberts <adarob@google.com>',\n",
      "                 'Afroz Mohiuddin <afrozm@google.com>',\n",
      "                 'Andrew Kondrich <andrewk1@stanford.edu>',\n",
      "                 'Billy Lamberta <blamb@google.com>',\n",
      "                 'Chanchal Kumar Maji '\n",
      "                 '<31502077+ChanchalKumarMaji@users.noreply.github.com>',\n",
      "                 'Christopher Suter <cgs@google.com>',\n",
      "                 'Copybara-Service <copybara-piper@google.com>',\n",
      "                 'Copybara-Service <copybara-worker@google.com>',\n",
      "                 'David Bieber <dbieber@google.com>',\n",
      "                 'Derek Murray <mrry@google.com>',\n",
      "                 'Dominic Jack <thedomjack@gmail.com>',\n",
      "                 'Drew Szurko <15271992+drewszurko@users.noreply.github.com>',\n",
      "                 'Dustin Tran <trandustin@google.com>',\n",
      "                 'Etienne Pot <epot@google.com>',\n",
      "                 'Jidin Dinesh <43285614+jidroid404@users.noreply.github.com>',\n",
      "                 'Jiri Simsa <jsimsa@google.com>',\n",
      "                 'Joel Shor <joelshor@google.com>',\n",
      "                 'K Yasaswi Sri Chandra Gandhi '\n",
      "                 '<yasaswisrichandragandhi@gmail.com>',\n",
      "                 'Lukas Geiger <lgeiger@users.noreply.github.com>',\n",
      "                 'Lukas Geiger <lukas.geiger94@gmail.com>',\n",
      "                 'Lukasz Kaiser <lukaszkaiser@google.com>',\n",
      "                 'Marcin Michalski <michalski@google.com>',\n",
      "                 'Mark Daoust <markdaoust@google.com>',\n",
      "                 'Noah Fiedel <nfiedel@google.com>',\n",
      "                 'Noam Shazeer <noam@google.com>',\n",
      "                 'Norman Mu <normanmu@google.com>',\n",
      "                 'Paige Bailey <webpaige@google.com>',\n",
      "                 'Parth Shandilya <parth1989shandilya@gmail.com>',\n",
      "                 'Pierre Ruyssen <pierrot@google.com>',\n",
      "                 'Ricardo Cuenca <jricardocuenca@gmail.com>',\n",
      "                 'Ryan Sepassi <rsepassi@gmail.com>',\n",
      "                 'Ryan Sepassi <rsepassi@google.com>',\n",
      "                 'Sergii Khomenko <khomenko@brainscode.com>',\n",
      "                 'Shivani Agrawal <shivaniagrawal@google.com>',\n",
      "                 'TensorFlow Datasets Team <no-reply@google.com>',\n",
      "                 'Yash Katariya <yashkatariya@google.com>',\n",
      "                 'ayush1999 <ayush.shridhar1999@gmail.com>',\n",
      "                 'brett koonce <koonce@hello.com>',\n",
      "                 'captain-pool <rickdey1998@gmail.com>',\n",
      "                 'ctiijima <ctiijima@us.ibm.com>',\n",
      "                 'us <22618852+us@users.noreply.github.com>',\n",
      "                 'us <rahmetsaritekin@gmail.com>'},\n",
      "             '2018_Q1': set(),\n",
      "             '2018_Q2': set(),\n",
      "             '2018_Q3': {'Afroz Mohiuddin <afrozm@google.com>',\n",
      "                         'Dustin Tran <trandustin@google.com>',\n",
      "                         'Ryan Sepassi <rsepassi@google.com>'},\n",
      "             '2018_Q4': {'Billy Lamberta <blamb@google.com>',\n",
      "                         'Derek Murray <mrry@google.com>',\n",
      "                         'Etienne Pot <epot@google.com>',\n",
      "                         'Marcin Michalski <michalski@google.com>',\n",
      "                         'Mark Daoust <markdaoust@google.com>',\n",
      "                         'Pierre Ruyssen <pierrot@google.com>',\n",
      "                         'Ryan Sepassi <rsepassi@gmail.com>',\n",
      "                         'TensorFlow Datasets Team <no-reply@google.com>',\n",
      "                         'brett koonce <koonce@hello.com>'},\n",
      "             '2019_Q1': {'Adam Roberts <adarob@google.com>',\n",
      "                         'Andrew Kondrich <andrewk1@stanford.edu>',\n",
      "                         'Chanchal Kumar Maji '\n",
      "                         '<31502077+ChanchalKumarMaji@users.noreply.github.com>',\n",
      "                         'Christopher Suter <cgs@google.com>',\n",
      "                         'Copybara-Service <copybara-piper@google.com>',\n",
      "                         'Copybara-Service <copybara-worker@google.com>',\n",
      "                         'David Bieber <dbieber@google.com>',\n",
      "                         'Dominic Jack <thedomjack@gmail.com>',\n",
      "                         'Drew Szurko '\n",
      "                         '<15271992+drewszurko@users.noreply.github.com>',\n",
      "                         'Jidin Dinesh '\n",
      "                         '<43285614+jidroid404@users.noreply.github.com>',\n",
      "                         'Jiri Simsa <jsimsa@google.com>',\n",
      "                         'Joel Shor <joelshor@google.com>',\n",
      "                         'K Yasaswi Sri Chandra Gandhi '\n",
      "                         '<yasaswisrichandragandhi@gmail.com>',\n",
      "                         'Lukas Geiger <lgeiger@users.noreply.github.com>',\n",
      "                         'Lukas Geiger <lukas.geiger94@gmail.com>',\n",
      "                         'Lukasz Kaiser <lukaszkaiser@google.com>',\n",
      "                         'Noah Fiedel <nfiedel@google.com>',\n",
      "                         'Noam Shazeer <noam@google.com>',\n",
      "                         'Norman Mu <normanmu@google.com>',\n",
      "                         'Paige Bailey <webpaige@google.com>',\n",
      "                         'Parth Shandilya <parth1989shandilya@gmail.com>',\n",
      "                         'Ricardo Cuenca <jricardocuenca@gmail.com>',\n",
      "                         'Sergii Khomenko <khomenko@brainscode.com>',\n",
      "                         'Shivani Agrawal <shivaniagrawal@google.com>',\n",
      "                         'Yash Katariya <yashkatariya@google.com>',\n",
      "                         'ayush1999 <ayush.shridhar1999@gmail.com>',\n",
      "                         'captain-pool <rickdey1998@gmail.com>',\n",
      "                         'ctiijima <ctiijima@us.ibm.com>',\n",
      "                         'us <22618852+us@users.noreply.github.com>',\n",
      "                         'us <rahmetsaritekin@gmail.com>'},\n",
      "             '2019_Q2': set(),\n",
      "             '2019_Q3': set(),\n",
      "             '2019_Q4': set()})\n"
     ]
    }
   ],
   "source": [
    "pprint(commiters_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2018_Q1': 0,\n",
      " '2018_Q2': 0,\n",
      " '2018_Q3': 10,\n",
      " '2018_Q4': 272,\n",
      " '2019_Q1': 414,\n",
      " '2019_Q2': 0,\n",
      " '2019_Q3': 0,\n",
      " '2019_Q4': 0}\n"
     ]
    }
   ],
   "source": [
    "pprint(commits_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing and reading from csv\n",
    "- Makes use of the [csv](https://docs.python.org/3/library/csv.html) python module - csv.writer and csv.reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = ['Quarter','# Commits','# Issues','# PullRequests','# NewCommitters','# NewIssueSubmitters','# NewPRSubmitters' ]\n",
    "\n",
    "with open('data.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for i, key in enumerate(indexes):\n",
    "        row = (indexes[i], commits_count[key], issue_count[key], pr_count[key], len(commiters_new[key]), len(iss_creators_new[key]), len(pr_senders_new[key]) )\n",
    "        writer.writerow(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the result as a table \n",
    "- Using the [csv](https://docs.python.org/3/library/csv.html) - csv.reader for accessing the csv and the [tabulate](https://pypi.org/project/tabulate/) python module for printing in tabular form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  ---------  --------  --------------  ---------------  --------------------  -----------------\n",
      "Quarter  # Commits  # Issues  # PullRequests  # NewCommitters  # NewIssueSubmitters  # NewPRSubmitters\n",
      "2018_Q1  0          0         0               0                0                     0\n",
      "2018_Q2  0          0         0               0                0                     0\n",
      "2018_Q3  10         4         1               3                3                     1\n",
      "2018_Q4  272        7         1               9                6                     1\n",
      "2019_Q1  414        312       175             30               71                    34\n",
      "2019_Q2  0          0         0               0                0                     0\n",
      "2019_Q3  0          0         0               0                0                     0\n",
      "2019_Q4  0          0         0               0                0                     0\n",
      "-------  ---------  --------  --------------  ---------------  --------------------  -----------------\n"
     ]
    }
   ],
   "source": [
    "with open('data.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    print(tabulate(reader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
